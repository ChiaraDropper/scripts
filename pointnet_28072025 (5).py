# -*- coding: utf-8 -*-
"""pointnet_28072025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UfX4JhZRaxDk_L3jIU7D0ncWgV8SbBO1
"""

# Installa versioni compatibili e stabili di torch e torchvision
!pip install --quiet --no-cache-dir torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Conferma la versione
import torch, torchvision
print("Torch:", torch.__version__)
print("Torchvision:", torchvision.__version__)


!pip install numpy matplotlib
# Pulisce tutto e installa versioni compatibili
!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# PointNet per classificazione ToF (empty, closed_door, one_person, two_people)

#import numpy as np
import math
import random
import os
import glob
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# Fix seed
#random.seed(42)

!unzip -q /content/TofNetDataset_clean.zip -d /content/dataset

# === STABILITY SEED ===
import random, numpy as np, torch
def set_seed(s=42):
    random.seed(s); np.random.seed(s); torch.manual_seed(s)
    torch.cuda.manual_seed_all(s)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
set_seed(42)

!pip install numpy==1.26.4
import numpy as np


import numpy as np

"""augmentatio"""

# === TRANSFORMATIONS ===
class RandRotationSmallZ(object):
    def __init__(self, deg=12):
        self.deg = deg
    def __call__(self, pointcloud):
        theta = np.deg2rad(np.random.uniform(-self.deg, self.deg))
        rot_matrix = np.array([[ np.cos(theta), -np.sin(theta), 0],
                               [ np.sin(theta),  np.cos(theta), 0],
                               [ 0,              0,             1]], dtype=np.float32)
        return pointcloud @ rot_matrix.T

class RandomJitter(object):
    def __init__(self, sigma=0.003, clip=0.015):
        self.sigma, self.clip = sigma, clip
    def __call__(self, pointcloud):
        noise = np.clip(np.random.normal(0, self.sigma, pointcloud.shape), -self.clip, self.clip)
        return pointcloud + noise

class RandomScale(object):
    def __init__(self, smin=0.97, smax=1.03):
        self.smin, self.smax = smin, smax
    def __call__(self, pointcloud):
        s = np.random.uniform(self.smin, self.smax)
        return pointcloud * s

class RandomDropout(object):
    def __init__(self, p=0.06):
        self.p = p
    def __call__(self, pointcloud):
        if self.p <= 0: return pointcloud
        mask = np.random.rand(pointcloud.shape[0]) > self.p
        return pointcloud[mask] if mask.any() else pointcloud

# === TRANSFORMATIONS ===
class PointSampler(object):
    def __init__(self, output_size):
        self.output_size = output_size

    def __call__(self, pointcloud):
        if pointcloud.shape[0] >= self.output_size:
            indices = np.random.choice(pointcloud.shape[0], self.output_size, replace=False)
        else:
            indices = np.random.choice(pointcloud.shape[0], self.output_size, replace=True)
        return pointcloud[indices, :]

class Normalize(object):
    def __call__(self, pointcloud):
        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)
        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))
        return norm_pointcloud



class ToTensor(object):
    def __call__(self, pointcloud):
        return torch.from_numpy(pointcloud).float()

# === DATASET ===

class ToFDoorBinDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.velo_dir = os.path.join(root_dir, 'velodyne')
        self.label_dir = os.path.join(root_dir, 'label_2')
        self.transform = transform

        self.label_map = {
            'none': 0,
            'one_person': 1,
            'two_people': 2
            }

        self.samples = []
        for fname in sorted(os.listdir(self.velo_dir)):
            if fname.endswith('.bin'):
                bin_path = os.path.join(self.velo_dir, fname)
                txt_path = os.path.join(self.label_dir, fname.replace('.bin', '.txt'))
                if os.path.exists(txt_path):
                    self.samples.append((bin_path, txt_path))

                # memorizza le label come interi per ogni sample (serve per split stratificato e pesi)
        self.labels = []
        for _, txt_path in self.samples:
            with open(txt_path, 'r') as f:
                line = f.readline().strip()
                if not line:
                    label_str = 'none'
                else:
                    label_str = line.split()[0]
            self.labels.append(self.label_map.get(label_str, 0))


    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        bin_path, txt_path = self.samples[idx]

        # Carica point cloud da .bin (N, 4) ‚Üí prendi solo x,y,z
        pc = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)[:, :3]

        # Leggi label da txt
        with open(txt_path, 'r') as f:
          lines = f.readlines()
          if not lines or lines[0].strip() == '':
              label_str = 'none'
          else:
              label_str = lines[0].strip().split()[0]

          #DEBUG print(f"Letto dal file {txt_path}: '{label_str}'")


          label = self.label_map.get(label_str, 0)




        if self.transform:
            pc = self.transform(pc)
        pc = torch.tensor(pc, dtype=torch.float32)  # qui converte in tensor
        return {'pointcloud': pc, 'category': label, 'bin_path': bin_path}


        #print("Etichette trovate nel dataset:")
        for _, txt_path in self.samples:
            with open(txt_path, 'r') as f:
                label_str = f.readline().strip()
                if not label_str:
                    label_str = 'none'
                #print(label_str)




        return {'pointcloud': pc, 'category': label, 'bin_path': bin_path}


# === POINTNET MODEL ===
class Tnet(nn.Module):
    def __init__(self, k=3):
        super().__init__()
        self.k = k
        self.conv1 = nn.Conv1d(k, 64, 1)
        self.conv2 = nn.Conv1d(64, 128, 1)
        self.conv3 = nn.Conv1d(128, 1024, 1)
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, k*k)
        self.bn1 = nn.BatchNorm1d(64)
        self.bn2 = nn.BatchNorm1d(128)
        self.bn3 = nn.BatchNorm1d(1024)
        self.bn4 = nn.BatchNorm1d(512)
        self.bn5 = nn.BatchNorm1d(256)

    def forward(self, x):
        bs = x.size(0)
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        x = torch.max(x, 2)[0]
        x = F.relu(self.bn4(self.fc1(x)))
        x = F.relu(self.bn5(self.fc2(x)))
        x = self.fc3(x)
        iden = torch.eye(self.k).repeat(bs, 1, 1).to(x.device)
        x = x.view(-1, self.k, self.k) + iden
        return x

class Transform(nn.Module):
    def __init__(self):
        super().__init__()
        self.input_transform = Tnet(k=3)
        self.feature_transform = Tnet(k=64)
        self.conv1 = nn.Conv1d(3, 64, 1)
        self.conv2 = nn.Conv1d(64, 128, 1)
        self.conv3 = nn.Conv1d(128, 1024, 1)
        self.bn1 = nn.BatchNorm1d(64)
        self.bn2 = nn.BatchNorm1d(128)
        self.bn3 = nn.BatchNorm1d(1024)

    def forward(self, x):
        matrix3x3 = self.input_transform(x)
        x = torch.bmm(matrix3x3, x)
        x = F.relu(self.bn1(self.conv1(x)))
        matrix64x64 = self.feature_transform(x)
        x = torch.bmm(matrix64x64, x)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.bn3(self.conv3(x))
        x = torch.max(x, 2)[0]
        return x, matrix3x3, matrix64x64

class PointNet(nn.Module):
    def __init__(self, classes=3):
        super().__init__()
        self.transform = Transform()
        self.fc1 = nn.Linear(1024, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, classes)
        self.bn1 = nn.BatchNorm1d(512)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout = nn.Dropout(p=0.3)
        self.logsoftmax = nn.LogSoftmax(dim=1)

    def forward(self, x):
        x, m3x3, m64x64 = self.transform(x)
        x = F.relu(self.bn1(self.fc1(x)))
        x = F.relu(self.bn2(self.dropout(self.fc2(x))))
        x = self.fc3(x)
        return self.logsoftmax(x), m3x3, m64x64

# === LOSS ===
def pointnetloss(outputs, labels, m3x3, m64x64, alpha=0.0001):
    criterion = nn.NLLLoss(weight=class_weights)  # <<‚Äî pesi di classe
    bs = outputs.size(0)
    id3x3 = torch.eye(3).repeat(bs, 1, 1).to(outputs.device)
    id64x64 = torch.eye(64).repeat(bs, 1, 1).to(outputs.device)
    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1,2))
    diff64x64 = id64x64 - torch.bmm(m64x64, m64x64.transpose(1,2))
    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3) + torch.norm(diff64x64)) / float(bs)

# === TRAINING ===
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
pointnet = PointNet().to(device)
optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)

from sklearn.metrics import f1_score

optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=12)

def eval_on(loader):
    pointnet.eval()
    correct = total = 0
    y_true, y_pred = [], []
    with torch.no_grad():
        for batch in loader:
            inputs = batch['pointcloud'].to(device)
            labels = batch['category'].to(device)
            outputs, _, _ = pointnet(inputs.transpose(1,2))
            _, preds = torch.max(outputs.data, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())
    acc = 100.0 * correct / max(total,1)
    f1m = f1_score(y_true, y_pred, average='macro') if total>0 else 0.0
    return acc, f1m

def train(model, train_loader, val_loader=None, epochs=20, save=True):
    best_f1, bad, patience = 0.0, 0, 3
    for epoch in range(epochs):
        model.train()
        running = 0.0
        for i, batch in enumerate(train_loader):
            inputs = batch['pointcloud'].to(device)
            labels = batch['category'].to(device)
            optimizer.zero_grad()
            outputs, m3x3, m64x64 = model(inputs.transpose(1,2))
            loss = pointnetloss(outputs, labels, m3x3, m64x64)
            loss.backward()
            optimizer.step()
            running += loss.item()
            if (i+1) % 10 == 0:
                print(f"[Epoch {epoch+1}, Batch {i+1}/{len(train_loader)}] loss: {running/10:.3f}")
                running = 0.0

        if val_loader:
            acc, f1m = eval_on(val_loader)
            print(f"Validation accuracy: {acc:.2f}% | F1-macro: {f1m:.4f}")
            if f1m > best_f1:
                best_f1, bad = f1m, 0
                if save: torch.save(model.state_dict(), "pointnet_best.pth")
            else:
                bad += 1
                if bad >= patience:
                    print("Early stopping."); break

        scheduler.step()

    if save:
        torch.save(model.state_dict(), "pointnet_last.pth")


# === ESEMPIO USO ===
#train_transforms = transforms.Compose([
 #   PointSampler(1024), Normalize(), RandRotation_z(), RandomNoise(), ToTensor()
#])

#nuove augmentation
train_transforms = transforms.Compose([
    Normalize(),
    RandRotationSmallZ(deg=12),
    RandomScale(0.97, 1.03),
    RandomJitter(0.003, 0.015),
    RandomDropout(0.06),
    PointSampler(1024) # Moved PointSampler here
    # ‚ùå niente ToTensor qui
])

val_transforms = transforms.Compose([
    Normalize(),
    PointSampler(1024) # PointSampler remains here
    # ‚ùå niente ToTensor qui
])



#train_dataset = ToFDoorBinDataset('/content/dataset/training', transform=train_transforms)
#from torch.utils.data import random_split

# Dataset intero
#full_dataset = ToFDoorBinDataset('/content/dataset/TofNetDataset_clean/training', transform=train_transforms)

# Suddividi 80% training, 20% validation
#train_size = int(0.8 * len(full_dataset))
#val_size = len(full_dataset) - train_size
#train_dataset, valid_dataset = random_split(full_dataset, [train_size, val_size])

#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
#valid_loader = DataLoader(valid_dataset, batch_size=64)

#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
from sklearn.model_selection import StratifiedShuffleSplit
from torch.utils.data import Subset

# Dataset base (senza transform qui, le applichiamo coi subset)
full_dataset = ToFDoorBinDataset('/content/dataset/TofNetDataset_clean/training', transform=None)

labels_all = np.array(full_dataset.labels)
idx_all = np.arange(len(full_dataset))
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, val_idx = next(sss.split(idx_all, labels_all))


from collections import Counter
train_labels = [full_dataset.labels[i] for i in train_idx]
cnt = Counter(train_labels)
K = 3
N = sum(cnt.values())
w = np.array([N / (K * max(cnt.get(c, 1), 1)) for c in range(K)], dtype=np.float32)
w = np.clip(w, 0.5, 2.0)
class_weights = torch.tensor(w, device=device)
print("Class weights:", w)

class TransformingSubset(Subset):
    def __init__(self, dataset, indices, transform):
        super().__init__(dataset, indices)
        self.dataset = dataset
        self.transform = transform
    def __getitem__(self, i):
      sample = super().__getitem__(i)
      pc, label, bin_path = sample['pointcloud'], sample['category'], sample['bin_path']

      # üîí garantisco numpy
      pc = np.array(pc, dtype=np.float32)

      # applico augmentation
      if self.transform:
          pc = self.transform(pc)

      # converto a torch solo alla fin
      pc = torch.tensor(pc, dtype=torch.float32)

      return {'pointcloud': pc, 'category': label, 'bin_path': bin_path}


train_transforms = transforms.Compose([
    Normalize(),
    RandRotationSmallZ(deg=12),
    RandomScale(0.97, 1.03),
    RandomJitter(0.003, 0.015),
    RandomDropout(0.06),
    PointSampler(1024) # Moved PointSampler here
])

val_transforms = transforms.Compose([
    Normalize(),
    PointSampler(1024) # PointSampler remains here
])

train_dataset = TransformingSubset(full_dataset, train_idx, train_transforms)
valid_dataset = TransformingSubset(full_dataset, val_idx, val_transforms)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, drop_last=True)
valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=2)


train(pointnet, train_loader, valid_loader, save=True)

# Puoi aggiungere valutazione e salvataggio modello dopo questa cella
def get_label_centroid(txt_path):
    with open(txt_path, 'r') as f:
        line = f.readline().strip()
        if not line:
            return None
        parts = line.split()
        if len(parts) < 14:
            return None
        try:
            # location_x, location_y, location_z
            x, y, z = map(float, parts[11:14])
            return np.array([x, y, z])
        except:
            return None
previous_center = None
in_count = 0
out_count = 0
axis = 1  # usa 1 per asse Y, oppure 2 per asse Z
delta_threshold = 100  # soglia in mm per movimento reale

def track_from_labels(current_center, frame_id):
    global previous_center, in_count, out_count

    if current_center is None:
        print(f"[Frame {frame_id}] ‚Üí Nessun centroide")
        return

    if previous_center is not None:
        delta = current_center[axis] - previous_center[axis]
        if abs(delta) > delta_threshold:
            if delta > 0:
                print(f"[Frame {frame_id}] ‚Üí Entrata (Œî = {delta:.1f} mm)")
                in_count += 1
            else:
                print(f"[Frame {frame_id}] ‚Üí Uscita (Œî = {delta:.1f} mm)")
                out_count += 1
        else:
            print(f"[Frame {frame_id}] ‚Üí Movimento troppo piccolo (Œî = {delta:.1f} mm)")
    else:
        print(f"[Frame {frame_id}] ‚Üí Primo centroide registrato")

    previous_center = current_center

def get_label_centroid(txt_path):
    with open(txt_path, 'r') as f:
        line = f.readline().strip()
        if not line:
            return None
        parts = line.split()
        if len(parts) < 14:
            return None
        try:
            # location_x, location_y, location_z
            x, y, z = map(float, parts[11:14])
            return np.array([x, y, z])
        except:
            return None
previous_center = None
in_count = 0
out_count = 0
axis = 1  # usa 1 per asse Y, oppure 2 per asse Z
delta_threshold = 100  # soglia in mm per movimento reale

def track_from_labels(current_center, frame_id):
    global previous_center, in_count, out_count

    if current_center is None:
        print(f"[Frame {frame_id}] ‚Üí Nessun centroide")
        return

    if previous_center is not None:
        delta = current_center[axis] - previous_center[axis]
        if abs(delta) > delta_threshold:
            if delta > 0:
                print(f"[Frame {frame_id}] ‚Üí Entrata (Œî = {delta:.1f} mm)")
                in_count += 1
            else:
                print(f"[Frame {frame_id}] ‚Üí Uscita (Œî = {delta:.1f} mm)")
                out_count += 1
        else:
            print(f"[Frame {frame_id}] ‚Üí Movimento troppo piccolo (Œî = {delta:.1f} mm)")
    else:
        print(f"[Frame {frame_id}] ‚Üí Primo centroide registrato")

    previous_center = current_center

!pip install plotly
import plotly.graph_objects as go
import random

def visualize_prediction(model, dataset, index=None):
    model.eval()
    if index is None:
        index = random.randint(0, len(dataset)-1)

    sample = dataset[index]
    pointcloud = sample['pointcloud'].unsqueeze(0).to(device)  # (1, N, 3)
    true_label = sample['category']

    with torch.no_grad():
        output, _, _ = model(pointcloud.transpose(1, 2))
        pred_label = output.max(dim=1)[1].item()

    # Convert to numpy for plotting
    pc_np = pointcloud.squeeze(0).cpu().numpy()
    x, y, z = pc_np[:, 0], pc_np[:, 1], pc_np[:, 2]

    label_map = ['none', 'one_person', 'two_people']
    true_label_str = label_map[true_label]
    pred_label_str = label_map[pred_label]
    # Aggiungi dopo aver ottenuto pred_label_str



    fig = go.Figure()

    fig.add_trace(go.Scatter3d(
        x=x, y=y, z=z,
        mode='markers',
        marker=dict(size=2, color=z, colorscale='Viridis'),
        name='Point Cloud'
    ))

    fig.update_layout(
        title=f"<b>Predicted:</b> {pred_label_str} &nbsp;&nbsp;&nbsp;&nbsp; <b>Ground Truth:</b> {true_label_str}",
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z',
        ),
        margin=dict(l=0, r=0, b=0, t=50)
    )

    fig.show()

def infer_direction_tracking(current_pc, frame_id):
    global previous_center, frame_counter, in_count, out_count

    # Calcola centroide 3D attuale
    current_center = np.mean(current_pc, axis=0)

    if previous_center is not None:
        # Verifica se √® la stessa persona (distanza spaziale)
        distance = np.linalg.norm(current_center - previous_center)

        if distance < DISTANCE_THRESHOLD:
            delta = current_center[DIRECTION_AXIS] - previous_center[DIRECTION_AXIS]

            if abs(delta) > DIRECTION_THRESHOLD:
                if delta > 0:
                    print(f"[Frame {frame_id}] ‚Üí Entrata (Œî = {delta:.1f} mm)")
                    in_count += 1
                else:
                    print(f"[Frame {frame_id}] ‚Üí Uscita (Œî = {delta:.1f} mm)")
                    out_count += 1
            else:
                print(f"[Frame {frame_id}] ‚Üí Movimento troppo piccolo (Œî = {delta:.1f} mm)")
        else:
            print(f"[Frame {frame_id}] ‚Üí Ignorato: nuova persona (Œîcentro = {distance:.1f} mm)")

    else:
        print(f"[Frame {frame_id}] ‚Üí Primo centroide registrato.")

    # aggiorna stato
    previous_center = current_center
    frame_counter += 1

# Stato del tracking
previous_center = None
frame_counter = 0
in_count = 0
out_count = 0
DIRECTION_AXIS = 1   # 1 = asse Y (dipende dalla tua scena)
DIRECTION_THRESHOLD = 150  # minimo movimento significativo in mm
DISTANCE_THRESHOLD = 300   # distanza massima per dire che √® la stessa persona

# Visualizzazione random
visualize_prediction(pointnet, valid_dataset)

# Oppure specifica un indice, es: il terzo esempio
visualize_prediction(pointnet, valid_dataset, index=20)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# Classi
label_names = ['none', 'one_person', 'two_people']

def evaluate_model(model, dataloader, label_names, show_cm=True):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in dataloader:
            inputs = batch['pointcloud'].to(device)
            labels = batch['category'].to(device)
            outputs, _, _ = model(inputs.transpose(1, 2))
            _, preds = torch.max(outputs.data, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)
    report = classification_report(all_labels, all_preds, target_names=label_names, digits=3, output_dict=True)
    report_df = pd.DataFrame(report).transpose()

    if show_cm:
        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt="d", xticklabels=label_names, yticklabels=label_names, cmap="Blues")
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.title("Confusion Matrix")
        plt.show()

    print("\nüìä Classification Report:")
    print(report_df)

    # Salva casi errati
    wrong_preds = [(true, pred) for true, pred in zip(all_labels, all_preds) if true != pred]
    print(f"\n‚ùå Number of misclassified examples: {len(wrong_preds)}")

    return report_df, cm, all_preds, all_labels



report_df, cm, preds, labels = evaluate_model(pointnet, valid_loader, label_names)

# STEP 1 ‚Äî Trova gli indici dei frame classificati male
wrong_indices = []

for i in range(len(valid_dataset)):
    sample = valid_dataset[i]
    pc = sample['pointcloud'].unsqueeze(0).to(device)
    true_label = sample['category']

    with torch.no_grad():
        output, _, _ = pointnet(pc.transpose(1, 2))
        pred_label = output.max(dim=1)[1].item()

    if pred_label != true_label:
        bin_path, txt_path = valid_dataset.dataset.samples[valid_dataset.indices[i]]
        wrong_indices.append((i, pred_label, true_label, bin_path, txt_path))

# STEP 2 ‚Äî Visualizza primi N errori (modifica N se vuoi)
print(f"\n‚ùå TOT errori: {len(wrong_indices)} ‚Äî ora visualizzo i primi 5...\n")

for i, (index, pred, true, bin_path, txt_path) in enumerate(wrong_indices):
    print(f"[{i+1}] Index {index} ‚Äî Pred: {label_names[pred]} | True: {label_names[true]}")
    print(f"     File: {bin_path}")
    visualize_prediction(pointnet, valid_dataset, index=index)

import os, numpy as np, pandas as pd, matplotlib.pyplot as plt
os.makedirs("misclassified_png", exist_ok=True)
label_names = ['none', 'one_person', 'two_people']

def softmax_np(logits):
    x = logits - logits.max(axis=1, keepdims=True)
    e = np.exp(x)
    return e / e.sum(axis=1, keepdims=True)

def save_pc_png(points, title, out_path):
    fig = plt.figure(figsize=(4,4))
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(points[:,0], points[:,1], points[:,2], s=0.5)
    ax.set_title(title)
    ax.set_axis_off()
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close(fig)

def dump_misclassified(model, dataset, loader, out_csv="misclassified.csv"):
    model.eval()
    rows = []
    with torch.no_grad():
        for batch_idx, batch in enumerate(loader):
            X = batch['pointcloud'].to(device)
            y = batch['category'].cpu().numpy()
            # prendo anche i path originali (occhio: random_split -> serve mappare indices)
            # Estraggo i bin_path allineati al batch:
            if hasattr(batch, 'keys') and 'bin_path' in batch:
                bin_paths = batch['bin_path']
            else:
                # ricavo dai subset indices:
                subset = loader.dataset  # Subset
                base_ds = subset.dataset
                bin_paths = [ base_ds.samples[ subset.indices[batch_idx*loader.batch_size + i] ][0]
                              for i in range(len(y)) if batch_idx*loader.batch_size + i < len(subset.indices) ]

            logits, _, _ = model(X.transpose(1,2))
            logits_np = logits.cpu().numpy()
            probs = softmax_np(logits_np)
            preds = probs.argmax(1)

            for i in range(len(y)):
                true_lbl = label_names[y[i]]
                pred_lbl = label_names[preds[i]]
                conf = float(probs[i, preds[i]])
                fid = os.path.splitext(os.path.basename(bin_paths[i]))[0]

                row = dict(frame_id=fid, y_true=true_lbl, y_pred=pred_lbl, conf=conf, bin_path=bin_paths[i])
                if true_lbl != pred_lbl:
                    # salva PNG anteprima
                    pts = np.fromfile(bin_paths[i], dtype=np.float32).reshape(-1,4)[:, :3]
                    png_path = f"misclassified_png/{fid}_true-{true_lbl}_pred-{pred_lbl}.png"
                    save_pc_png(pts, f"{fid} | true:{true_lbl} pred:{pred_lbl} | N={len(pts)}", png_path)
                    row["png"] = png_path
                else:
                    row["png"] = ""
                rows.append(row)

    df = pd.DataFrame(rows)
    mis = df[df.y_true != df.y_pred].sort_values(["y_true","conf"])
    df.to_csv("all_predictions.csv", index=False)
    mis.to_csv(out_csv, index=False)
    print(f"üíæ Salvati: {out_csv}, all_predictions.csv e PNG in misclassified_png/")
    print(f"‚ùå Misclassified: {len(mis)}")
    return mis, df

mis, all_df = dump_misclassified(pointnet, valid_dataset, valid_loader)